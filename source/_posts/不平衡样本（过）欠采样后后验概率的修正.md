---
title: 不平衡样本（过）欠采样后后验概率的修正
date: 2019-03-27 19:35:11
categories: 机器学习
tags:
- 不平衡样本
- 贝叶斯理论
- 先验概率
- 后验概率
- 似然估计
description: 最近在项目当中遇到了不平衡样本，并且由于本身样本总量受取数的时间窗口限制的原因，样本已经不平衡到无法建模的地步，在扩大取样窗口的同时也瞄了一眼业务上线以来所有的标签为1的样本数量，也少到了不得不进行欠采样来进行平衡才能够愉快的建模的地步。而样本分布的改变（先验概率）比如对模型的预测概率（后验概率）有所影响，为了能够将模型结果能够准确地在新数据（假设与抽样前样本同分布）进行部署，需要根据抽样前后的先验概率对模型预测的后验概率进行修正。
---

## 背景介绍
在有监督的分类任务当中，常常会出现训练样本当中的关于类别的先验概率与训练后的分类器实际要跑的数据存在差异。举个例子，假设要训练一个是否患某种疾病的分类器，训练样本当中患病:健康的比例是1:1，那么训练样本当中两类的先验概率都将是0.5。当我们将训练后的模型在实际当中应用的时候，我们不了解对于这种疾病实际上的先验概率应该是多少，这个必须从新的数据当中进行估计，同时，模型的结果也需要相应地进行调整。换句话说，分类模型是基于先验概率与实际情况不同样本进行训练的。

在这种情况下，基于以下几点原因，对于现实数据的先验概率若有所了解的话将显得非常重要：
- 贝叶斯决策优化是基于类别的先验概率，以观察到的数据为条件来推断后验概率
- 很多分类方法，包括神经网络分类器，提供对于分类后验概率的估计。这意味着如果将这些分类器应用在与训练样本有着不同先验概率的数据时会降低分类器的准确率

上面的背景介绍基本来自[Adjusting the Outputs of a Classiﬁer to New a Priori Probabilities: A Simple Procedure](http://www.isys.ucl.ac.be/staff/marco/Publications/Saerens2002a.pdf)这篇文章，下面再具体介绍下该文当中提到的一种修正后验概率的方法。

## 基于先验概率的后验概率估计
### 分类数据

假设我们要基于向量${X}$预测未知的离散响应变量${\omega}$，这个离散变量的取值为$\Omega=(\omega_{1},...\omega_{n})$，一共$n$个类别标签。

训练集当中各个类别的先验概率用$p_t(\omega_1)$表示，在之前的是否分患病的分类器当中，$$p_t(\omega_1)=p_t(disease)=0.5$$$$p_t(\omega_2)=p_t(no\_disease)=0.5$$

我们用$\hat{p_t}(\omega_i|x)$来表示基于以上数据训练所得分类器对$\omega_i$类预测所得的后验概率，假设特征向量$X$已经在训练集的条件下观测得到。分类模型的算法可以是神经网络、逻辑回归或者可以基于观测对后验概率进行估计的其它算法。

然后我们将训练好的分类模型应用到另外一个数据集，为了对先验概率进行区分，待预测的数据集的先验概率用$p_t(\omega_i)$进行表示，以示与$\hat{p_t}(\omega_i)$的不同。模型为这些新数据所预测的后验概率需要进行修正。

原文作者就两种情况进行了论述，新数据集的先验概率$\hat{p}(\omega_i)$是否已知，考虑到项目上的应用场景，本文仅就第一种情况，也就是先验概率已知的情况下进行介绍，因为对于抽样来讲，原数据集的先验概率显然是已知的。

### 新数据集先验概率已知情况下的后验概率修正

首先，我们选择训练样本是基于类别标签$\omega_i$的偏差，而不是特征向量$X$的偏差，因此类别内分布(within-class densities)，$p(X|\omega_i)$并不会因为先验概率的改变而改变，也就是意味着无论是训练样本还是待预测的新样本，类内分布是相同的。假设

根据贝叶斯定理：$$\hat{p_t}(X|\omega_i)=\frac{\hat{p_t}(\omega_i|X)\hat{p_t}(X)}{\hat{p_t}(\omega_i)}       $$

后验概率$\hat{p_t}(\omega_i|X)$基于新数据集的观测$X$，然后应用训练后的模型获得，是基于训练集条件的后验概率估计。 

修正的后验概率，$\hat{p}(\omega_i|X)$，通过贝叶斯定理可以得到同样的方程：$$\hat{p}(X|\omega_i)=\frac{\hat{p}(\omega_i|X)\hat{p}(X)}{\hat{p}(\omega_i)}$$

因为无论是训练数据还是现实待预测数据，类内分布相同，即：$$\hat{p}(X|\omega_i)=\hat{p_t}(X|\omega_i)$$

我们定义$f(X)=\frac{\hat{p_t}(X)}{p_t(X)}$，结合以上两个方程有：$$\hat{p}(\omega_i|X)=f(X)\frac{\hat{p}(\omega_i)}{\hat{p_t}(\omega_i)}{\hat{p_t}(\omega_i|X)}$$

又因为$\sum_{i=1}^n\hat{p}(\omega_i|X)=1$，对上式两边加$\sum$号，则等号左边正好为$1$，可以得到：$$f(X)=[\sum_{j=1}^n\frac{\hat{p}(\omega_j)}{\hat{p_t}(\omega_j)}\hat{p_t}(\omega_j|X)]^{-1}$$

这里用$j$作为求和符号的下标是为了与$f(X)$当中的$i$进行区分。

最后有：$$\hat{p}(\omega_i|X)=\frac{\frac{\hat{p}(\omega_i)}{\hat{p_t}(\omega_i)}\hat{p_t}(\omega_i|X)}{\sum_{j=1}^n\frac{\hat{p}(\omega_j)}{\hat{p_t}(\omega_j)}\hat{p_t}(\omega_j|X)}$$

这个公式可以用来对后验概率$\hat{p}(\omega_i|X)$进行修正。

## 举例说明

下面这篇文章：[不平衡数据集过（欠）采样后预测概率的调整](https://blog.csdn.net/nickzzzhu/article/details/83821372)有一个更加具体的例子，有兴趣的读者可以进一步阅读。






