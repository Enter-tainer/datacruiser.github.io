---
title: 逻辑回归在贷款推荐模型上面的实践
date: 2019-03-20 15:14:14
categories: 机器学习
tags:
- 逻辑回归
- 推荐系统
- 互联网金融
- 导流
description: 最近在公司做的一个项目，根据运营增加营收、提高平台上面各个三方合规贷款业务的通过率的需求，主要使用逻辑回来来预测每个用户在平台上面不同贷款业务的通过概率，然后向用户按照通过概率排序展示TOP N的产品，从而提高转化。项目实施后，在切部分流量进行 AB 测试以后，无论是整体的贷款申请通过率还是营收，均有较大幅度的提升，目前正在准备向全平台进行推广，这边主要分享下主要的思路和方法。
---



## 需求背景

本人所在公司是一个导流平台，主要的业务是撮合贷款，并根据第三方在平台上面的放款额抽取一定的佣金。因此，比起贷款的贷后表现，更加看重的是通过率，从逻辑上讲，排除平台本身的市场获客、引导用户进行业务申请不说，申请的高通过率是高放款的重要前提。于是通过率并成为一个很关键的指标，鉴于平台上接入的第三方有银行系、消费金融公司等不同资金成本和风控偏好的公司，如果将平台上的用户匹配上合适的贷款业务，增加向用户定向推荐和投放最适合他的产品以提高申请通过率自然而然成为一个非常明确的需求。

## 业务现状

理想非常丰满，但是现实总是略显骨感。由于平台数据架构等一系列的原因，目前的现状主要有以下两点：

- 现有的用户画像太笼统，无法对用户进行有效分层
- 现有的推荐规则过于简单，无法有效向用户推荐其申请通过概率较高的产品

在这样的现状下，我们就思考能否利用现有的数据对用户在各个贷款产品上面的申请通过概率进行建模预测。稍微捋一捋思路，我们发现基于以下两点假设，这个模型还是可以建起来跑跑看的。

- 用户首次申请是否通过会影响用户再次申请的意愿

这一点假设其实更加凸显了向用户定向投放和展示根据其资质条件所匹配的贷款产品的重要性，对于首次申请的用户群体的通过率将会严重影响他们后续在平台上面的活跃和留存，在这一点如果没有优化好会增加平台的获客成本。

- 不同机构的风险偏好确实存在差异

这一点假设非常重要，如果接入平台的各个机构的风险偏好相同，那么通过概率的排序就没有意义，因为这将意味着一个用户在每个产品的通过概率都是相同的。显然，考虑到每个机构自身资金成本、产品利率、产品额度区间、产品期限等都是不同，大概率来讲，这个假设是成立的。

## 解决方案
### 标签定义
因为是要预测用户申请的通过概率，这个标签定义非常明确，申请通过的用户为1，为通过为0。

### 变量准备

变量还是一些金融领域里面常规的边缘数据，比如运营商、公积金等，都是用户在申请贷款业务的时候授权爬取的。当然，特征工程还是必须的，根据业务逻辑会从爬取的原始详单中衍生出几百个特征。

### 模型构建

前面的思路清楚以后，模型构建相对简单。考虑到公司目前并没有决策引擎，后端也是以`PHP`为主，一些负责的树类模型也无法通过`PMML`文件进行后续的部署。本着从无到有，快速上线，测试迭代的思路还是选择了逻辑回归来构建模型，模型输出的参数明了，开发起来也相对简单。

在这个阶段，需要就每一个业务建立一个模型。假设平台上面有`N`个产品，那么当一个用户进来的时候，会带着他的数据去跑`N`个模型，产生`N`个通过概率，可以将这些通过概率持久化到数据库当中，后面进行贷款产品推荐展示的时候可以选择`TOP N`个产品进行展示。

上面这种是简单横向对面各个产品的通过概率，实现起来比较简单，大部分的计算可以在业务端就可以完成。另外，考虑每个产品本身申请通过率的不同，简单横向比较不同模型计算得出的通过概率，会有一定的弊端，另外一种是先纵向确定用户在该产品内通过概率的排名，然后再横向再对这个排名进行排序，然后再推荐排名的`TOP N`个产品。示意图如下：
![示意图](https://i.imgur.com/1xV4kju.png)

后面这种方式需要对存量用户的历史数据根据模型计算通过概率，有一定的计算量，在传统的单机`MySQL`数仓的架构下，对于百万以及千万级的数据基本无能为力。

### 模型部署

因为采用了逻辑回归算法，因此部署起来相对简单。 
假设 $p(y=1|\boldsymbol{x})$ 为用户通过的概率，通过sigmoid函数 $y=1/(1+e^{-z})$ 将线性回归模型 $z=\boldsymbol{w}^T\boldsymbol{x}+b$ 产生的预测值进行转换后得到：$$\ln\frac{p}{1-p}=z=\boldsymbol{w}^T\boldsymbol{x}+b$$

通过建模可以得到$\boldsymbol{w}^T$和 $b$，那么根据每个用户画像及其它数据维度可以得到代表该用户的 $\boldsymbol{x}$。每个模型的参数（$\boldsymbol{w}^T$和 $b$）可以预先在数据库当中进行配置，对于$\boldsymbol{x}$分两种情况，有些不太经常变动的数据可以在数仓当中提前计算好，用`T-1`的数据，有些实时性要求高的数据则需要在业务端算好。这样直接硬写代码很容易将$\boldsymbol{w}^T\boldsymbol{x}+b$计算出来，如果用`logit`来表示这个结果的话，那么最终的通过概率就是：$$p(通过|\boldsymbol{x})=\frac{e^{logit}}{1+e^{logit}}$$

### 模型测试

模型测试主要关注两个方面，首先是模型的效果，就是所需要优化的业务指标，通过率是否真的有所提升。可以分时间先后进行测试，有条件也可以进行 AB 测试，后面的方式更加具有说服力。

另外一个是模型本身的稳定性，这个可以通过比较模型上线后跑的通过概率分布与建模时样本的通过概率分布之间的差异是否在可控范围内，相关的指标主要是`群体稳定性指标(population stability index)`，计算公式如下：$$PSI=\sum_{i=1}^B(y_{i}-y_{b_i})\ln(\frac{y_{i}}{y_{b_i}})$$



其中 $y_{i}$ 是模型上线后跑过模型的用户通过概率各个分箱的比例，而 $y_{b_i}$ 则是建模样本通过概率各个分箱的比例。
## 测试结果

本模型开发部署以后一共在线测试了一个月，其中 AB 测试一共用了一周时间，不管是上线前后的数据对比，还是 AB 测试时是否用模型进行推荐的对比，都表明模型在提高用户贷款申请通过率方面有较好的效果。基于这样的测试结果，目前正在考虑向全平台推广应用该模型。

## 总结

- 最重要的一点是验证了这个方法切实可行；
- 目前需要对每一个业务单独建模，业务数量多了以后会导致模型较多，增加维护难度；
- 后续可以考虑其它机器学习算法，比如树类的相关算法，GBDT、XGBOOST等；
- 在数据架构允许的情况下，应该对存量用户的历史数据也跑模型，以用户在各个产品的通过排名来进行排序和推荐。












